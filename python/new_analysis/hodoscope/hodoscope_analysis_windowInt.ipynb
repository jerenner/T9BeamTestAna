{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21901544",
   "metadata": {},
   "source": [
    "# Hodoscope analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17abc9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uproot\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import hodoscope_functions_win as hd\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm, moyal, binned_statistic\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import hodoscope_constants_win\n",
    "chg_cuts_tight = hodoscope_constants_win.chg_cuts_tight\n",
    "chg_cuts_wide = hodoscope_constants_win.chg_cuts_wide\n",
    "chg_ranges_wide = hodoscope_constants_win.chg_ranges_wide\n",
    "\n",
    "#pd.options.display.max_columns = 500\n",
    "#pd.options.display.max_rows = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76961037",
   "metadata": {},
   "source": [
    "# 1. Gamma peak analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af4a9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntuple_dir = \"/Users/jrenner/local/data/beamtest/ntuple_files/\"\n",
    "ntuple_pd_dir = \"/Users/jrenner/temp/hk/beamtest/ntuple_dataframes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f766e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [735]\n",
    "rmomenta = [800]\n",
    "#runs = [731, 732, 733, 734, 735, 736, 737, 738, 753, 754, 755, 756, 760, 763, 764, 765]\n",
    "#rmomenta = [460, 500, 600, 700, 800, 900, 1000, 1200, 500, 600, 700, 800, 1000, 900, 1200, 800]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034aee4c",
   "metadata": {},
   "source": [
    "## 1a. Multi-run analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef478a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing run 735 ...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Column not found: WindowIntPE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/05/5x88pkbj3yb7x2vwsxtwvmdm0000gn/T/ipykernel_31177/1478311285.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Run the timing analysis (event selection).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mfinal_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntot_evts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntot_spills\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntot_tagged_evts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharge_analysis_corrected_winInt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchg_cuts_wide\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Save the results of the gamma peak fits for plotting later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/jerenner/T9BeamTestAna/python/new_analysis/hodoscope/hodoscope_functions_win.py\u001b[0m in \u001b[0;36mcharge_analysis_corrected_winInt\u001b[0;34m(df_dict, chg_cuts, low_radiation, debug)\u001b[0m\n\u001b[1;32m    752\u001b[0m                                     + tof0_combined[chg_key+'_03']) / 4.\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m     \u001b[0mtof0_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TOF0_combined\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtof0_combined\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'avg_charge'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchg_cuts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TOF00'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m     \u001b[0mtof0_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'hit_TOF0'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/jerenner/T9BeamTestAna/python/new_analysis/hodoscope/hodoscope_functions_win.py\u001b[0m in \u001b[0;36mfilter_range\u001b[0;34m(name, df, key, rng, drop, chg_key, debug)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;31m# Otherwise choose the one with the maximum integrated charge.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'event'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchg_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m             \u001b[0mdf_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniforge3/lib/python3.9/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1536\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m             )\n\u001b[0;32m-> 1538\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniforge3/lib/python3.9/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column not found: {key}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: WindowIntPE'"
     ]
    }
   ],
   "source": [
    "# Run the gamma peak analysis for all runs.\n",
    "all_fit_results, all_fit_arrays = [], []\n",
    "all_ntot_evts, all_ntot_spills, all_ntot_tagged_evts = [], [], []\n",
    "for rnum, pbeam in zip(runs, rmomenta):\n",
    "    \n",
    "    print(\"Processing run\",rnum,\"...\")\n",
    "    df_dict = hd.read_dataframes_from_csv(\"/Users/jrenner/local/jerenner/T9BeamTestAna/ntuple_dataframes/old/run000{}_win\".format(rnum))\n",
    "    \n",
    "    # Run the timing analysis (event selection).\n",
    "    final_df, ntot_evts, ntot_spills, ntot_tagged_evts = hd.charge_analysis_corrected_winInt(df_dict, chg_cuts_wide)\n",
    "    \n",
    "    # Save the results of the gamma peak fits for plotting later.\n",
    "    fit_results, fit_arrays = hd.gamma_peak_plots(final_df, rnum, pbeam, base_dir='plt/gamma_peaks', nbins=80, range=[0,0.8])\n",
    "    \n",
    "    all_fit_results.append(fit_results)\n",
    "    all_fit_arrays.append(fit_arrays)\n",
    "    all_ntot_evts.append(ntot_evts)\n",
    "    all_ntot_spills.append(ntot_spills)\n",
    "    all_ntot_tagged_evts.append(ntot_tagged_evts)\n",
    "    \n",
    "all_fit_results = np.array(all_fit_results)\n",
    "all_fit_arrays = np.array(all_fit_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f449063",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(final_df[final_df.total_hits == 1]))\n",
    "print(ntot_tagged_evts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2337e225",
   "metadata": {},
   "source": [
    "#### Summary of data (*tbl.data*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73da8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print table of results.\n",
    "for rnum,p,nevts,nspills in zip(runs, rmomenta, all_ntot_evts, all_ntot_spills):\n",
    "    print(f\"{rnum} & {p} & {nevts} & {nspills} & \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c0b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_ntot_tagged_evts/np.array(all_ntot_evts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3afcf8",
   "metadata": {},
   "source": [
    "#### Tagged events per spill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ceee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "all_ntot_spills = np.array(all_ntot_spills)\n",
    "all_ntot_tagged_evts = np.array(all_ntot_tagged_evts)\n",
    "\n",
    "ax.plot(rmomenta,all_ntot_tagged_evts/all_ntot_spills,'o',color='black')\n",
    "ax.set_ylim([0,400])\n",
    "ax.set_xlabel(\"Beam momentum (MeV/c)\",fontsize=14)\n",
    "ax.set_ylabel(\"Tagged photons/spill\",fontsize=14)\n",
    "plt.savefig(\"tagged_evts_per_spill.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abaaf2d",
   "metadata": {},
   "source": [
    "#### Lead glass calibration plot (*fig.LG_calibration*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae8f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all gamma peak means and fit lines on the same plot.\n",
    "elec_hit_momenta_values = [v for v in hd.elec_hit_momenta.values()]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "momentum_color = {460: \"red\", 500: \"orange\", 600: \"yellow\", 700: \"green\", \n",
    "                  800: \"blue\", 900: \"violet\", 1000: \"gray\", 1100: \"brown\", 1200: \"black\"}\n",
    "momentum_plt   = {460: False, 500: False, 600: False, 700: False,\n",
    "                  800: False, 900: False, 1000: False, 1100: False, 1200: False}\n",
    "\n",
    "all_e_gamma_expected = []\n",
    "for run_momentum, fit_array in zip(rmomenta,all_fit_arrays):\n",
    "    \n",
    "    # Get the fit means and errors for this run.\n",
    "    fit_means, fit_smeans = fit_array[0], fit_array[1]\n",
    "\n",
    "    e_gamma_expected = [run_momentum - mval*1000 for mval in elec_hit_momenta_values[::-1]]\n",
    "    all_e_gamma_expected.append(e_gamma_expected)\n",
    "    \n",
    "    if(not momentum_plt[run_momentum]):\n",
    "        ax.errorbar(e_gamma_expected, fit_means, yerr=fit_smeans, fmt='.', \n",
    "                    color=momentum_color[run_momentum], label=f\"p = {run_momentum} MeV/c\")\n",
    "        momentum_plt[run_momentum] = True\n",
    "    else:\n",
    "        ax.errorbar(e_gamma_expected, fit_means, yerr=fit_smeans, fmt='.', \n",
    "                    color=momentum_color[run_momentum])\n",
    "        \n",
    "# Fit a line to all results at once.\n",
    "all_fit_means = all_fit_arrays[:,0,:].flatten()\n",
    "all_fit_smeans = all_fit_arrays[:,1,:].flatten()\n",
    "all_e_gamma_expected = np.array(all_e_gamma_expected).flatten()\n",
    "\n",
    "p0 = [(np.max(all_e_gamma_expected) - np.min(all_e_gamma_expected))/(np.max(all_fit_means) - np.min(all_fit_means)),all_e_gamma_expected[0]]\n",
    "popt, pcov = curve_fit(hd.line, all_e_gamma_expected, all_fit_means, p0, sigma=all_fit_smeans)\n",
    "x = np.linspace(50, 1120, 1000)\n",
    "y = hd.line(x, *popt)\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "#ax.plot(x, y, label='C = $({:.2f} \\pm {:.2f}) x 10^{{-4}} \\cdot $p + $({:.3f} \\pm {:.4f})$'.format(popt[0]*10000,perr[0]*10000,popt[1],perr[1]), color='red', alpha=0.8, linewidth=3, linestyle=':')\n",
    "ax.plot(x, y, color='black', alpha=0.8, linewidth=1, linestyle='-')\n",
    "ax.annotate(\"---- C = $({:.2f} \\pm {:.2f}) x 10^{{-4}} \\cdot $E + $({:.3f} \\pm {:.4f})$\".format(popt[0]*10000,perr[0]*10000,popt[1],perr[1]), xy=(500, 0.10), xytext=(200, 0.01), fontsize=14, fontweight='bold', color='black')\n",
    "\n",
    "ax.legend(title=\"Beam momentum\",title_fontsize=12,fontsize=11)\n",
    "ax.set_ylabel('Lead glass charge [arbitrary units]',fontsize=14)\n",
    "ax.set_xlabel('Expected energy [MeV]',fontsize=14)\n",
    "ax.tick_params(axis=\"x\", labelsize=14)\n",
    "ax.tick_params(axis=\"y\", labelsize=14)\n",
    "plt.savefig(\"LG_calibration.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78eb8ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the slope and intercept of the calibration curve vs. momentum\n",
    "mvals = all_fit_results[:,0]\n",
    "merr = all_fit_results[:,1]\n",
    "bvals = all_fit_results[:,2]\n",
    "berr = all_fit_results[:,3]\n",
    "fvals = all_fit_results[:,4]\n",
    "ferr = all_fit_results[:,5]\n",
    "cvals = all_fit_results[:,6]\n",
    "cerr = all_fit_results[:,7]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "flat_axes = axes.ravel()\n",
    "\n",
    "flat_axes[0].errorbar(rmomenta,mvals*10000,yerr=merr*10000,fmt='o')\n",
    "flat_axes[0].set_xlabel('Beam momentum (MeV/c)',fontsize=20)\n",
    "flat_axes[0].set_ylabel('Slope $x 10^{-4}$ (LG charge)/MeV',fontsize=20)\n",
    "flat_axes[0].tick_params(axis=\"x\", labelsize=14)\n",
    "flat_axes[0].tick_params(axis=\"y\", labelsize=14)\n",
    "\n",
    "flat_axes[1].errorbar(rmomenta,bvals,yerr=berr,fmt='o')\n",
    "flat_axes[1].set_xlabel('Beam momentum (MeV/c)',fontsize=20)\n",
    "flat_axes[1].set_ylabel('Intercept (LG charge)',fontsize=20)\n",
    "flat_axes[1].tick_params(axis=\"x\", labelsize=14)\n",
    "flat_axes[1].tick_params(axis=\"y\", labelsize=14)\n",
    "\n",
    "flat_axes[2].errorbar(rmomenta,fvals,yerr=ferr,fmt='o')\n",
    "flat_axes[2].set_xlabel('Beam momentum (MeV/c)',fontsize=20)\n",
    "flat_axes[2].set_ylabel('Parameter F',fontsize=20)\n",
    "flat_axes[2].tick_params(axis=\"x\", labelsize=14)\n",
    "flat_axes[2].tick_params(axis=\"y\", labelsize=14)\n",
    "\n",
    "flat_axes[3].errorbar(rmomenta,cvals,yerr=cerr,fmt='o')\n",
    "flat_axes[3].set_xlabel('Beam momentum (MeV/c)',fontsize=20)\n",
    "flat_axes[3].set_ylabel('Parameter C',fontsize=20)\n",
    "flat_axes[3].tick_params(axis=\"x\", labelsize=14)\n",
    "flat_axes[3].tick_params(axis=\"y\", labelsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebcf1d8",
   "metadata": {},
   "source": [
    "## 1b. Single-run analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46583637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(x, amplitude, mean, stddev):\n",
    "        return amplitude * norm.pdf(x, loc=mean, scale=stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82df004",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in all dataframes from a given run\n",
    "rnum = 735\n",
    "low_radiation = False\n",
    "pbeam = 800\n",
    "tail_threshold = 2.6\n",
    "df_dict = hd.read_dataframes_from_csv(f\"{ntuple_pd_dir}run000{rnum}_win\")\n",
    "df_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a50a9d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict['HD0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7443b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing_plot(detname, pk_times, t_range, nbins, normed=False, logscale=False):\n",
    "\n",
    "    # Create the plot\n",
    "    hist, bin_edges = np.histogram(pk_times, bins=nbins, range=t_range, density=normed)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    # Gaussian fit\n",
    "    fit_start = 0\n",
    "    fit_end = -1\n",
    "    initial_params = [np.max(hist), np.mean(pk_times), np.std(pk_times)]\n",
    "    print(f\"Initial params: {initial_params}\")\n",
    "    popt, pcov = curve_fit(gauss, bin_centers[fit_start:fit_end], hist[fit_start:fit_end], p0=initial_params)\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "    fit_curve = gauss(bin_centers[fit_start:fit_end], *popt)\n",
    "\n",
    "    # Plot the fit peak\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    plt.bar(bin_edges[:-1], hist, width=np.diff(bin_edges)[0], align='edge', color='white')\n",
    "    plt.plot(bin_edges[:-1], hist, color='black', drawstyle='steps-post')\n",
    "    plt.plot(bin_centers[fit_start:fit_end], fit_curve, '--', color='red', linewidth=2.0, alpha=1.0)\n",
    "\n",
    "    # Prepare the legend.\n",
    "    lbl1 = f\"{detname}\"\n",
    "    lbl2 = \"$\\mu$ = {:.4f} $\\pm$ {:.4f}\".format(popt[1],perr[1])\n",
    "    lbl3 = \"$\\sigma$ = {:.4f} $\\pm$ {:.4f}\".format(popt[2],perr[2])\n",
    "    legend_elements = [Line2D([0], [0], color='none', lw=0, label=lbl1),\n",
    "                       Line2D([0], [0], color='none', lw=0, label=lbl2),\n",
    "                       Line2D([0], [0], color='none', lw=0, label=lbl3)]\n",
    "    leg = plt.legend(handles=legend_elements, frameon=True, handlelength=0, fontsize=16)\n",
    "    for i, text in enumerate(leg.get_texts()):\n",
    "        if i == 0:\n",
    "            text.set_weight('bold')\n",
    "        text.set_horizontalalignment('right')\n",
    "\n",
    "    plt.xlabel(\"SignalTimeCorrected\",fontsize=18)\n",
    "    plt.ylabel(\"Counts/bin\",fontsize=18)\n",
    "    plt.gca().tick_params(axis=\"x\", labelsize=14)\n",
    "    plt.gca().tick_params(axis=\"y\", labelsize=14)\n",
    "    if(logscale): plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b2d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make timing plots for all detectors using the SignalTimeCorrected branch\n",
    "# Consider the time for all detectors relative to TOF10\n",
    "pk_times = df_dict['TOF10']['WindowCentralTimeCorrected']\n",
    "t_range = [45,100]\n",
    "nbins = 23\n",
    "normed = False\n",
    "timing_plot('TOF10',pk_times,t_range,nbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4f5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut on events with peaks in TOF10 at the selected values\n",
    "df_T1sel = hd.filter_range('TOF10',df_dict['TOF10'],'WindowCentralTimeCorrected',[60,86],drop=True,debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cad682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_constants():\n",
    "    import importlib\n",
    "    importlib.reload(hodoscope_constants_win)\n",
    "    global chg_cuts_tight, chg_cuts_wide, chg_ranges_wide\n",
    "    chg_cuts_tight = hodoscope_constants_win.chg_cuts_tight\n",
    "    chg_cuts_wide = hodoscope_constants_win.chg_cuts_wide\n",
    "    chg_ranges_wide = hodoscope_constants_win.chg_ranges_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a286e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from hodoscope_constants_win import chg_cuts_tight, chg_cuts_wide, chg_ranges_wide\n",
    "reload_constants()\n",
    "\n",
    "# Assign the charge cuts\n",
    "chg_cuts = chg_cuts_wide\n",
    "chg_range = chg_ranges_wide\n",
    "\n",
    "# Plot the charge cuts\n",
    "evt_list = None #evt_list_TAIL\n",
    "lbl = ''\n",
    "evt_list_2 = None #evt_list_PEAK\n",
    "lbl_2 = 'PEAK'\n",
    "select_nonzero_peaks = True\n",
    "windowInt = True\n",
    "quantity = 'WindowIntPE'\n",
    "logscale = False\n",
    "nbins = 50\n",
    "normed = True\n",
    "\n",
    "# Create a grid of 8 rows x 4 columns\n",
    "fig, axes = plt.subplots(8, 4, figsize=(24, 28))\n",
    "flat_axes = axes.ravel()\n",
    "\n",
    "fig.suptitle(f'Run {rnum}', fontsize=24, y=0.9)\n",
    "\n",
    "# Iterate based on the custom order\n",
    "for key, ax in zip(hd.custom_order, flat_axes):\n",
    "    df = df_dict[key]\n",
    "    \n",
    "    # Select only non-zero peaks if specified.\n",
    "    if(select_nonzero_peaks):\n",
    "        if(windowInt):\n",
    "            df_select = df[df['nWindowPeaks'] > 0]\n",
    "        else:\n",
    "            df_select = df[df['nPeaks'] > 0]\n",
    "    # Otherwise, this quantity is event-wide: only keep 1 entry for each event.\n",
    "    else:\n",
    "        df_select = df.drop_duplicates(subset=['event'], keep='first')\n",
    "\n",
    "    # Place a cut if we're plotting PeakVoltage or IntCharge.\n",
    "    #if((key[0:2] == 'HD' or key == 'PbGlass') and (quantity == 'IntCharge' or quantity == 'PeakVoltage' or quantity == 'MaxVoltage' or quantity == 'WindowIntCharge' or quantity == 'WholeWaveformInt' or quantity == 'WindowIntPE')):\n",
    "    if(quantity == 'IntCharge' or quantity == 'PeakVoltage' or quantity == 'MaxVoltage' or quantity == 'WindowIntCharge' or quantity == 'WholeWaveformInt' or quantity == 'WindowIntPE'):\n",
    "        df_select = df_select[df_select[quantity] > 1e-2]\n",
    "\n",
    "    # Cut on the selected events if an event list is provided.\n",
    "    if(not(evt_list is None)):\n",
    "        print(f\"[{key}] before selection {len(df_select)}\")\n",
    "        \n",
    "        df_select_1 = df_select[df_select['event'].isin(evt_list)]\n",
    "        print(f\"[{key}] selecting out {len(evt_list)} events to get {len(df_select_1)}\")\n",
    "        \n",
    "        if(not(evt_list_2 is None)):\n",
    "            df_select_2 = df_select[df_select['event'].isin(evt_list_2)]\n",
    "            print(f\"[{key}] selecting out {len(evt_list_2)} events to get {len(df_select_2)}\")\n",
    "    else:\n",
    "        df_select_1 = df_select\n",
    "\n",
    "    # Plot histogram for the current signal on its corresponding axis\n",
    "    hist_charge, bin_edges_charge = np.histogram(df_select_1[quantity], bins=nbins, density=normed, range=chg_range[key])\n",
    "    bin_centers_charge = (bin_edges_charge[:-1] + bin_edges_charge[1:]) / 2\n",
    "    ax.bar(bin_edges_charge[:-1], hist_charge, width=np.diff(bin_edges_charge)[0], align='edge', color='white')\n",
    "    ax.plot(bin_edges_charge[:-1], hist_charge, color='black', drawstyle='steps-post', label=f\"{key} ({lbl})\")\n",
    "    \n",
    "    if(not(evt_list_2 is None)):\n",
    "        hist_charge_2, bin_edges_charge_2 = np.histogram(df_select_2[quantity], bins=nbins, density=normed, range=chg_range[key])\n",
    "        bin_centers_charge_2 = (bin_edges_charge_2[:-1] + bin_edges_charge_2[1:]) / 2\n",
    "        ax.bar(bin_edges_charge_2[:-1], hist_charge_2, width=np.diff(bin_edges_charge_2)[0], align='edge', color='white')\n",
    "        ax.plot(bin_edges_charge_2[:-1], hist_charge_2, color='red', drawstyle='steps-post', label=f\"{key} ({lbl_2})\")\n",
    "\n",
    "    #n, bins, patches = ax.hist(df_select[quantity], bins=nbins, edgecolor='black', alpha=0.7, label=key)  # capture output to use in legend\n",
    "    ax.axvline(chg_cuts[key][0],color='black',linestyle='--')\n",
    "    ax.axvline(chg_cuts[key][1],color='black',linestyle='--')\n",
    "    #ax.set_title(key)\n",
    "    ax.set_xlabel(quantity)\n",
    "    ax.set_ylabel('Counts/bin')\n",
    "    ax.legend()  # Add legend\n",
    "\n",
    "    if(logscale and ((\"ACT0\" in key) or (\"ACT1\" in key) or (\"TriggerScint\"))):\n",
    "        ax.set_yscale('log')\n",
    "        \n",
    "plt.savefig(f\"{quantity}.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ba0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hodoscope_constants import time_ranges_wide, time_ranges_tight, timing_cuts_wide, timing_cuts_tight\n",
    "\n",
    "# Select which timing cuts to use\n",
    "time_ranges = time_ranges_wide\n",
    "timing_cuts = timing_cuts_wide\n",
    "\n",
    "# Plot the timing cuts\n",
    "evt_list = evt_list_TAIL\n",
    "lbl = 'TAIL'\n",
    "evt_list_2 = evt_list_PEAK\n",
    "lbl_2 = 'PEAK'\n",
    "select_nonzero_peaks = True\n",
    "windowInt = True\n",
    "logscale = False\n",
    "normed = True\n",
    "nbins = 50\n",
    "\n",
    "# Create a grid of 8 rows x 4 columns\n",
    "fig, axes = plt.subplots(8, 4, figsize=(26, 34))\n",
    "flat_axes = axes.ravel()\n",
    "\n",
    "fig.suptitle(f'Run {rnum}', fontsize=24, y=0.9)\n",
    "\n",
    "# Iterate based on the custom order\n",
    "for key, ax in zip(hd.custom_order, flat_axes):\n",
    "\n",
    "    # Select the detector.\n",
    "    df_detector = df_dict[key]\n",
    "    \n",
    "    # Apply charge cuts.\n",
    "    df_detector = df_detector[(df_detector.WindowIntCharge > chg_cuts[key][0]) & (df_detector.WindowIntCharge < chg_cuts[key][1])]\n",
    "    \n",
    "    # Cut on the selected events if an event list is provided.\n",
    "    if(not(evt_list is None)):\n",
    "        print(f\"[{key}] before selection {len(df_select)}\")\n",
    "        \n",
    "        df_sel_1 = df_detector[df_detector['event'].isin(evt_list)]\n",
    "        print(f\"[{key}] selecting out {len(evt_list)} events to get {len(df_sel_1)}\")\n",
    "        \n",
    "        if(not(evt_list_2 is None)):\n",
    "            df_sel_2 = df_detector[df_detector['event'].isin(evt_list_2)]\n",
    "            print(f\"[{key}] selecting out {len(evt_list_2)} events to get {len(df_sel_2)}\")\n",
    "    else:\n",
    "        df_sel_1 = df_detector\n",
    "        df_sel_2 = df_detector\n",
    "    \n",
    "    # Create the plot\n",
    "    pk_times_1 = df_sel_1['WindowCentralTimeCorrected'] - df_sel_1['SignalTimeMatchedTOF1']\n",
    "    hist_1, bin_edges_1 = np.histogram(pk_times_1, bins=nbins, range=time_ranges[key], density=normed)\n",
    "    bin_centers_1 = (bin_edges_1[:-1] + bin_edges_1[1:]) / 2\n",
    "    ax.bar(bin_edges_1[:-1], hist_1, width=np.diff(bin_edges_1)[0], align='edge', color='white')\n",
    "    ax.plot(bin_edges_1[:-1], hist_1, color='black', drawstyle='steps-post', label=f'{key} ({lbl})')\n",
    "    #print(f\"Mean for {key} is {pk_times_1.mean()}: cuts [{pk_times_1.mean()-5:.1f},{pk_times_1.mean()+5:.1f}]\")\n",
    "    #print(f\"\\'{key}\\': [{pk_times_1.mean()-5:.1f},{pk_times_1.mean()+5:.1f}]\")\n",
    "    \n",
    "    if(not(evt_list_2 is None)):\n",
    "        pk_times_2 = df_sel_2['WindowCentralTimeCorrected'] - df_sel_2['SignalTimeMatchedTOF1']\n",
    "        hist_2, bin_edges_2 = np.histogram(pk_times_2, bins=nbins, range=time_ranges[key], density=normed)\n",
    "        bin_centers_2 = (bin_edges_2[:-1] + bin_edges_2[1:]) / 2\n",
    "        ax.bar(bin_edges_2[:-1], hist_2, width=np.diff(bin_edges_2)[0], align='edge', color='white')\n",
    "        ax.plot(bin_edges_2[:-1], hist_2, color='red', drawstyle='steps-post', label=f'{key} ({lbl_2})')\n",
    "    \n",
    "    #ax.axvline(timing_cuts[key][0],color='black',linestyle='--')\n",
    "    #ax.axvline(timing_cuts[key][1],color='black',linestyle='--')\n",
    "    ax.legend(fontsize=14)\n",
    "\n",
    "    ax.set_xlabel(f\"WindowCentralTimeCorrected-SignalTimeMatchedTOF1\",fontsize=12)\n",
    "    ax.set_ylabel(\"Counts/bin\",fontsize=14)\n",
    "    ax.tick_params(axis=\"x\", labelsize=14)\n",
    "    ax.tick_params(axis=\"y\", labelsize=14)\n",
    "    if(logscale): ax.set_yscale('log')\n",
    "        \n",
    "plt.savefig(f\"timing.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df, ntot_evts, ntot_spills, ntot_tagged_evts = hd.timing_analysis_corrected_winInt(df_dict, chg_cuts, timing_cuts, low_radiation=low_radiation, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358cb4fd",
   "metadata": {},
   "source": [
    "### Timing cut table (*tbl.timingcuts*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85237de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print timing cut table\n",
    "cuts_hd14      = (final_df.hit_HD14 == 1)\n",
    "cuts_hd14_tail = cuts_hd14 & (final_df.LG_WholeWaveformInt <  tail_threshold) #& (final_df.LG_IntCharge > 0.01375)\n",
    "cuts_hd14_peak = cuts_hd14 & (final_df.LG_WholeWaveformInt >= tail_threshold)\n",
    "\n",
    "# Total numbers of events \n",
    "tot_hd14 = len(final_df[cuts_hd14])\n",
    "tot_hd14_peak = len(final_df[cuts_hd14_peak])\n",
    "tot_hd14_tail = len(final_df[cuts_hd14_tail])\n",
    "\n",
    "# Cuts to evaluate.\n",
    "cuts_ACT0      = (final_df.hit_ACT0 == 1)\n",
    "cuts_ACT1      = (final_df.hit_ACT1 == 1)\n",
    "cuts_ACT3      = (final_df.nohit_ACT3 == 1)\n",
    "cuts_TOF0      = (final_df.hit_TOF0 == 1)\n",
    "cuts_TOF1      = (final_df.hit_TOF1 == 1)\n",
    "cuts_T2        = (final_df.hit_T2 == 1)\n",
    "cuts_all       = cuts_ACT0 & cuts_ACT1 & cuts_TOF0 & cuts_TOF1 & cuts_T2 # & cuts_ACT3\n",
    "\n",
    "# Arrays for iterating through the cuts.\n",
    "cuts_txt = [\"HD14 hit only\", \"ACT0 hit\", \"ACT1 hit\", \"ACT3 no hit\", \"TOF0 hit\", \"TOF1 hit\", \"T2 hit\", \"All\"]\n",
    "cuts_arr = [cuts_hd14, cuts_ACT0, cuts_ACT1, cuts_ACT3, cuts_TOF0, cuts_TOF1, cuts_T2, cuts_all]\n",
    "\n",
    "print(\"Cut & All evts (\\\\%) & Peak evts (\\\\%) & Tail evts (\\\\%)\\\\\\\\\")\n",
    "print(\"\\hline\")\n",
    "for txt,cuts in zip(cuts_txt,cuts_arr):\n",
    "    nall  = len(final_df[cuts_hd14 & cuts])\n",
    "    npeak = len(final_df[cuts_hd14_peak & cuts])\n",
    "    ntail = len(final_df[cuts_hd14_tail & cuts])\n",
    "    \n",
    "    print(f\"{txt} & {nall} ({nall/tot_hd14*100:.0f}) & {npeak} ({npeak/tot_hd14_peak*100:.0f}) & {ntail} ({ntail/tot_hd14_tail*100:.0f})\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba02397",
   "metadata": {},
   "source": [
    "#### Gamma peaks plot (*fig.gamma_peaks*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89acf52c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fit_results, fit_arrays = hd.gamma_peak_plots(final_df, rnum, pbeam, base_dir='plt/gamma_peaks', nbins=80, range=[0,0.8], timing_cuts=False, low_radiation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828eb671",
   "metadata": {},
   "source": [
    "#### Timing and charge cuts plot for HD14 (*fig.hd14_cuts*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee65c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the timing and charge selections for HD14.\n",
    "\n",
    "# Set up the figure.\n",
    "fig, axes = plt.subplots(2, 1, figsize=(8, 10))\n",
    "flat_axes = axes.ravel()\n",
    "ax0, ax1 = flat_axes[0], flat_axes[1]\n",
    "\n",
    "# Select the timing and charge information from the HD14 peaks dataframe.\n",
    "df_hd14 = df_dict['HD14']\n",
    "hd14_timing = df_hd14[(df_hd14.PeakTime > 0) & (df_hd14.IntCharge > 0.1)]['PeakTime']\n",
    "#hd14_timing = df_hd14[df_hd14.PeakTime > 0]['PeakTime']\n",
    "hd14_charge = df_hd14[df_hd14.IntCharge > 0.02]['IntCharge']\n",
    "\n",
    "# Plot the timing information with cuts shown.\n",
    "hist_timing, bin_edges_timing = np.histogram(hd14_timing, bins=50, range=[50,150])\n",
    "bin_centers_timing = (bin_edges_timing[:-1] + bin_edges_timing[1:]) / 2\n",
    "ax0.bar(bin_edges_timing[:-1], hist_timing, width=np.diff(bin_edges_timing)[0], align='edge', color='white')\n",
    "ax0.plot(bin_edges_timing[:-1], hist_timing, color='black', drawstyle='steps-post')\n",
    "ax0.axvline(hd_timing_ranges['HD14'][0],color='black',linestyle='--')\n",
    "ax0.axvline(hd_timing_ranges['HD14'][1],color='black',linestyle='--')\n",
    "ax0.set_xlabel(\"HD14 Peak Time (samples)\",fontsize=14)\n",
    "ax0.set_ylabel('Counts/bin',fontsize=14)\n",
    "ax0.tick_params(axis=\"x\", labelsize=14)\n",
    "ax0.tick_params(axis=\"y\", labelsize=14)\n",
    "\n",
    "# Plot the charge information with cuts shown.\n",
    "hist_charge, bin_edges_charge = np.histogram(hd14_charge, bins=50, range=[0,0.6])\n",
    "bin_centers_charge = (bin_edges_charge[:-1] + bin_edges_charge[1:]) / 2\n",
    "ax1.bar(bin_edges_charge[:-1], hist_charge, width=np.diff(bin_edges_charge)[0], align='edge', color='white')\n",
    "ax1.plot(bin_edges_charge[:-1], hist_charge, color='black', drawstyle='steps-post')\n",
    "ax1.axvline(hd_charge_ranges['HD14'][0],color='black',linestyle='--')\n",
    "ax1.axvline(hd_charge_ranges['HD14'][1],color='black',linestyle='--')\n",
    "ax1.set_xlabel(\"HD14 integrated charge (arbitrary units)\",fontsize=14)\n",
    "ax1.set_ylabel('Counts/bin',fontsize=14)\n",
    "ax1.tick_params(axis=\"x\", labelsize=14)\n",
    "ax1.tick_params(axis=\"y\", labelsize=14)\n",
    "plt.savefig(\"HD14_cuts.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcdc1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the timing and charge selections for T2.\n",
    "\n",
    "# Set up the figure.\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "flat_axes = axes.ravel()\n",
    "ax0, ax1 = flat_axes[0], flat_axes[1]\n",
    "\n",
    "# Select the timing and charge information from the HD14 peaks dataframe.\n",
    "df_T2 = df_dict['TriggerScint']\n",
    "#T2_timing = df_T2[(df_T2.PeakTime > 0) & (df_T2.IntCharge > 0.0)]['PeakTime']\n",
    "T2_timing = df_T2[(df_T2.SignalTimeCorrected > 0) & (df_T2.IntCharge > 0.0)]['SignalTimeCorrected']\n",
    "T2_charge = df_T2[df_T2.IntCharge > 0.0]['IntCharge']\n",
    "\n",
    "# Plot the timing information with cuts shown.\n",
    "hist_timing, bin_edges_timing = np.histogram(T2_timing, bins=30, range=[20,100])\n",
    "bin_centers_timing = (bin_edges_timing[:-1] + bin_edges_timing[1:]) / 2\n",
    "ax0.bar(bin_edges_timing[:-1], hist_timing, width=np.diff(bin_edges_timing)[0], align='edge', color='white')\n",
    "ax0.plot(bin_edges_timing[:-1], hist_timing, color='black', drawstyle='steps-post')\n",
    "ax0.axvline(t2_timing_range[0],color='black',linestyle='--')\n",
    "ax0.axvline(t2_timing_range[1],color='black',linestyle='--')\n",
    "ax0.set_xlabel(\"T2 Peak Time (samples)\",fontsize=14)\n",
    "ax0.set_ylabel('Counts/bin',fontsize=14)\n",
    "ax0.tick_params(axis=\"x\", labelsize=14)\n",
    "ax0.tick_params(axis=\"y\", labelsize=14)\n",
    "\n",
    "# Plot the charge information with cuts shown.\n",
    "hist_charge, bin_edges_charge = np.histogram(T2_charge, bins=50, range=[0,0.125])\n",
    "bin_centers_charge = (bin_edges_charge[:-1] + bin_edges_charge[1:]) / 2\n",
    "ax1.bar(bin_edges_charge[:-1], hist_charge, width=np.diff(bin_edges_charge)[0], align='edge', color='white')\n",
    "ax1.plot(bin_edges_charge[:-1], hist_charge, color='black', drawstyle='steps-post')\n",
    "ax1.axvline(t2_charge_range[0],color='black',linestyle='--')\n",
    "ax1.axvline(t2_charge_range[1],color='black',linestyle='--')\n",
    "ax1.set_xlabel(\"T2 integrated charge (arbitrary units)\",fontsize=14)\n",
    "ax1.set_ylabel('Counts/bin',fontsize=14)\n",
    "ax1.tick_params(axis=\"x\", labelsize=14)\n",
    "ax1.tick_params(axis=\"y\", labelsize=14)\n",
    "plt.savefig(\"T2_cuts.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679ea084",
   "metadata": {},
   "source": [
    "#### HD14 histogram (*fig.gamma_peak_H14*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(x, amplitude, mean, stddev):\n",
    "        return amplitude * norm.pdf(x, loc=mean, scale=stddev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8e7f2",
   "metadata": {},
   "source": [
    "Uncalibrated histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee362392",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 50\n",
    "e_range = [0,13]\n",
    "fit_start = 10\n",
    "fit_end = 40\n",
    "normed = False\n",
    "cuts_nominal = (final_df.hit_HD14 == 1) & (final_df.total_hits == 1) & (final_df.LG_nWindowPeaks == 1)\n",
    "\n",
    "# Set up the timing cuts\n",
    "if(low_radiation):\n",
    "    cuts_timing = (final_df.hit_ACT1 == 1) & (final_df.nohit_ACT3 == 1) & \\\n",
    "              (final_df.hit_TOF0 == 1) & (final_df.hit_T2 == 1)\n",
    "else:\n",
    "    cuts_timing = (final_df.hit_ACT0 == 1) & \\\n",
    "                        (final_df.hit_ACT1 == 1) & \\\n",
    "                        (final_df.hit_TOF0 == 1) & (final_df.hit_TOF1 == 1) & (final_df.hit_T2 == 1)\n",
    "                        #(final_df.nohit_ACT3 == 1) & \\\n",
    "\n",
    "# Convert the LG charge to energy\n",
    "#lg_energy = final_df[cuts_nominal & (final_df.hit_TOF0 == 1)]['LG_WindowIntPE']\n",
    "lg_energy = final_df[cuts_nominal & cuts_timing]['LG_WindowIntPE']\n",
    "#lg_energy = lg_energy[lg_energy > 50]\n",
    "\n",
    "# Create the plot\n",
    "hist, bin_edges = np.histogram(lg_energy, bins=nbins, range=e_range, density=normed)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "# Gaussian fit\n",
    "initial_params = [np.max(hist), np.mean(lg_energy), np.std(lg_energy)]\n",
    "print(f\"Initial params: {initial_params}\")\n",
    "popt, pcov = curve_fit(gauss, bin_centers[fit_start:fit_end], hist[fit_start:fit_end], p0=initial_params)\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "fit_curve = gauss(bin_centers[fit_start:fit_end], *popt)\n",
    "        \n",
    "# Plot the fit peak\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "plt.bar(bin_edges[:-1], hist, width=np.diff(bin_edges)[0], align='edge', color='white')\n",
    "plt.plot(bin_edges[:-1], hist, color='black', drawstyle='steps-post')\n",
    "plt.plot(bin_centers[fit_start:fit_end], fit_curve, '--', color='red', linewidth=2.0, alpha=1.0)\n",
    "plt.axvline(tail_threshold,color='black',linestyle='--')\n",
    "\n",
    "# Prepare the legend.\n",
    "lbl1 = f\"H14 DATA\"\n",
    "lbl2 = \"$\\mu$ = {:.4f} $\\pm$ {:.4f}\".format(popt[1],perr[1])\n",
    "lbl3 = \"$\\sigma$ = {:.4f} $\\pm$ {:.4f}\".format(popt[2],perr[2])\n",
    "legend_elements = [Line2D([0], [0], color='none', lw=0, label=lbl1),\n",
    "                   Line2D([0], [0], color='none', lw=0, label=lbl2),\n",
    "                   Line2D([0], [0], color='none', lw=0, label=lbl3)]\n",
    "leg = plt.legend(handles=legend_elements, frameon=True, handlelength=0, fontsize=16)\n",
    "for i, text in enumerate(leg.get_texts()):\n",
    "    if i == 0:\n",
    "        text.set_weight('bold')\n",
    "    text.set_horizontalalignment('right')\n",
    "\n",
    "plt.xlabel(\"Lead glass WindowIntPE\",fontsize=18)\n",
    "plt.ylabel(\"Counts/bin\",fontsize=18)\n",
    "plt.gca().tick_params(axis=\"x\", labelsize=14)\n",
    "plt.gca().tick_params(axis=\"y\", labelsize=14)\n",
    "\n",
    "plt.savefig(f\"DATA_gamma_peak_H14.pdf\", bbox_inches='tight')\n",
    "#plt.yscale('log')\n",
    "#plt.ylim([0.1,np.max(h0[0])*1.5])\n",
    "#plt.title(f\"RUN 000{rnum}, p = + {pbeam/1000} GeV/c\",fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03003de",
   "metadata": {},
   "source": [
    "Calibrated histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee482ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nbins = 50\n",
    "e_range = [0,700]\n",
    "fit_start = 15\n",
    "fit_end = 45\n",
    "normed = True\n",
    "cuts_nominal = (final_df.hit_HD14 == 1) & (final_df.total_hits == 1) & (final_df.LG_nPeaks == 1)\n",
    "ecal_b = -0.017\n",
    "ecal_m = 6.15e-4\n",
    "\n",
    "# Set up the timing cuts\n",
    "if(low_radiation):\n",
    "    cuts_timing = (final_df.hit_ACT1 == 1) & (final_df.nohit_ACT3 == 1) & \\\n",
    "              (final_df.hit_TOF0 == 1) & (final_df.hit_T2 == 1)\n",
    "else:\n",
    "    cuts_timing = (final_df.hit_ACT0 == 1) & \\\n",
    "                        (final_df.hit_ACT1 == 1) & \\\n",
    "                        (final_df.hit_TOF0 == 1) & (final_df.hit_TOF1 == 1) & (final_df.hit_T2 == 1)\n",
    "                        #(final_df.nohit_ACT3 == 1) & \\\n",
    "\n",
    "# Convert the LG charge to energy\n",
    "lg_energy = (final_df[cuts_nominal & cuts_timing]['LG_IntCharge'] - ecal_b) / ecal_m\n",
    "lg_energy = lg_energy[lg_energy > 50]\n",
    "\n",
    "# Create the plot\n",
    "hist, bin_edges = np.histogram(lg_energy, bins=nbins, range=e_range, density=normed)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "# Gaussian fit\n",
    "initial_params = [np.max(hist), np.mean(lg_energy), np.std(lg_energy)]\n",
    "print(f\"Initial params: {initial_params}\")\n",
    "popt, pcov = curve_fit(gauss, bin_centers[fit_start:fit_end], hist[fit_start:fit_end], p0=initial_params)\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "fit_curve = gauss(bin_centers[fit_start:fit_end], *popt)\n",
    "        \n",
    "# Plot the fit peak\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "plt.bar(bin_edges[:-1], hist, width=np.diff(bin_edges)[0], align='edge', color='white')\n",
    "plt.plot(bin_edges[:-1], hist, color='black', drawstyle='steps-post')\n",
    "plt.plot(bin_centers[fit_start:fit_end], fit_curve, '--', color='red', linewidth=2.0, alpha=1.0)\n",
    "\n",
    "# Prepare the legend.\n",
    "lbl1 = f\"H14 DATA\"\n",
    "lbl2 = \"$\\mu$ = {:.4f} $\\pm$ {:.4f}\".format(popt[1],perr[1])\n",
    "lbl3 = \"$\\sigma$ = {:.4f} $\\pm$ {:.4f}\".format(popt[2],perr[2])\n",
    "legend_elements = [Line2D([0], [0], color='none', lw=0, label=lbl1),\n",
    "                   Line2D([0], [0], color='none', lw=0, label=lbl2),\n",
    "                   Line2D([0], [0], color='none', lw=0, label=lbl3)]\n",
    "leg = plt.legend(handles=legend_elements, frameon=True, handlelength=0, fontsize=16)\n",
    "for i, text in enumerate(leg.get_texts()):\n",
    "    if i == 0:\n",
    "        text.set_weight('bold')\n",
    "    text.set_horizontalalignment('right')\n",
    "\n",
    "plt.xlabel(\"Lead glass energy (MeV)\",fontsize=18)\n",
    "plt.ylabel(\"Counts/bin\",fontsize=18)\n",
    "plt.gca().tick_params(axis=\"x\", labelsize=14)\n",
    "plt.gca().tick_params(axis=\"y\", labelsize=14)\n",
    "\n",
    "plt.savefig(f\"DATA_gamma_peak_H14.pdf\", bbox_inches='tight')\n",
    "#plt.yscale('log')\n",
    "#plt.ylim([0.1,np.max(h0[0])*1.5])\n",
    "#plt.title(f\"RUN 000{rnum}, p = + {pbeam/1000} GeV/c\",fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a48fed",
   "metadata": {},
   "source": [
    "#### Plot the timing for the peak and tail events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbfbe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_T1sel\n",
    "df_peak = final_df[cuts_nominal & cuts_timing & (final_df.LG_WindowIntPE >= tail_threshold)]\n",
    "evt_list_PEAK = np.array(df_peak.event.values)\n",
    "df_tail = final_df[cuts_nominal & cuts_timing & (final_df.LG_WindowIntPE < tail_threshold)]\n",
    "evt_list_TAIL = np.array(df_tail.event.values)\n",
    "#plt.hist(df_tail['LG_IntCharge'],bins=40)\n",
    "#peak_T1 = df_peak.merge(df_T1sel, on='event', suffixes=('', '_T1'))\n",
    "#peak_T1['SignalTimeCorrected_rel'] = peak_T1['SignalTimeCorrected'] - peak_T1['SignalTimeCorrected_T1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(evt_list_PEAK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd8ed37",
   "metadata": {},
   "source": [
    "#### Select the peak and tail events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec04815",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hd14 = final_df[cuts_nominal & cuts_timing]\n",
    "evts_tail = df_hd14[df_hd14['LG_IntCharge'] < 0.1].event\n",
    "energy_tail = df_hd14[df_hd14['LG_IntCharge'] < 0.1].LG_IntCharge\n",
    "print(\"Tail events:\",len(evts_tail))\n",
    "evts_peak = df_hd14[(df_hd14['LG_IntCharge'] >= 0.1) & (df_hd14['LG_IntCharge'] < 0.4)].event\n",
    "energy_peak = df_hd14[df_hd14['LG_IntCharge'] >= 0.1].LG_IntCharge\n",
    "print(\"Peak events:\",len(evts_peak))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efacc4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Peak events\")\n",
    "print(evts_peak.values[0:40])\n",
    "\n",
    "print(\"Tail events\")\n",
    "evts_tail.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a53807",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_tail.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e217703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PbGlass = df_dict['TOF00']\n",
    "df_PbGlass[df_PbGlass.event == 165]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b86509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict['HD14']['event'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a7296a",
   "metadata": {},
   "source": [
    "#### Consider the timing difference between the LG and HD14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248e378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the peaks in each detector element for the events in the peak and tail.\n",
    "df_HD = df_dict['HD14']\n",
    "df_HD_peak = df_HD[df_HD['event'].isin(evts_peak)]\n",
    "df_HD_tail = df_HD[df_HD['event'].isin(evts_tail)]\n",
    "df_LG = df_dict['PbGlass']\n",
    "df_LG_peak = df_LG[df_LG['event'].isin(evts_peak)]\n",
    "df_LG_tail = df_LG[df_LG['event'].isin(evts_tail)]\n",
    "\n",
    "# Handle duplicates in the HD array (rare cases in which we had multiple HD peaks but only 1 made cuts)\n",
    "u, c = np.unique(df_HD_tail['event'], return_counts=True)\n",
    "nduplicates = np.sum(c[c > 1])\n",
    "print(nduplicates,\"duplicate events in HD tail\")\n",
    "if(nduplicates > 0): \n",
    "    print(\"Dropping duplicates in HD peak dataframe ...\")\n",
    "    df_HD_peak = df_HD_peak.drop_duplicates(subset=['event'], keep='first')\n",
    "\n",
    "u, c = np.unique(df_HD_peak['event'], return_counts=True)\n",
    "nduplicates = np.sum(c[c > 1])\n",
    "print(np.sum(c[c > 1]),\"duplicate events in HD peak\")\n",
    "if(nduplicates > 0): \n",
    "    print(\"Dropping duplicates in HD tail dataframe ...\")\n",
    "    df_HD_tail = df_HD_tail.drop_duplicates(subset=['event'], keep='first')\n",
    "\n",
    "# Get the tail time differences.\n",
    "tdiff_tail = []\n",
    "for evt,t_LG in zip(df_LG_tail['event'].values,df_LG_tail['PeakTime'].values):\n",
    "    t_HD = df_HD_tail[df_HD_tail['event'] == evt]['PeakTime'].values[0]\n",
    "    tdiff_tail.append(t_LG - t_HD)\n",
    "\n",
    "# Get the peak time differences.\n",
    "tdiff_peak = []\n",
    "for evt,t_LG in zip(df_LG_peak['event'].values,df_LG_peak['PeakTime'].values):\n",
    "    t_HD = df_HD_peak[df_HD_peak['event'] == evt]['PeakTime'].values[0]\n",
    "    tdiff_peak.append(t_LG - t_HD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2abff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tdiff_tail,bins=40,label=\"Tail events\",alpha=0.6)\n",
    "plt.hist(tdiff_peak,bins=40,label=\"Peak events\",alpha=0.6)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('PeakTime$_{LG}$ - PeakTime$_{HD14}$',fontsize=14)\n",
    "plt.ylabel(\"Counts/bin\",fontsize=14)\n",
    "plt.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4146da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ct = np.unique(df_HD_peak['event'],return_counts=True)\n",
    "print(\"Maximum at\",np.argmax(ct))\n",
    "df_HD_peak[df_HD_peak['event'] == 23243]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580500ba",
   "metadata": {},
   "source": [
    "#### Plot 2D histograms for the peak and tail events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9c57d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd.plot_2D_histogram(df_dict, evt_list=evts_peak, detector1=\"HD14\", quantity1=\"PeakTime\", detector2=\"TOF10\", quantity2=\"PeakTime\", base_dir='plt_2d_peak', rnum=rnum, select_nonzero_peaks=True, logscale=False, nbins=20, range=[[75,125],[60,100]])\n",
    "hd.plot_2D_histogram(df_dict, evt_list=evts_peak, detector1=\"HD14\", quantity1=\"PeakTime\", detector2=\"TOF00\", quantity2=\"PeakTime\", base_dir='plt_2d_peak', rnum=rnum, select_nonzero_peaks=True, logscale=False, nbins=20, range=[[75,125],[40,90]])\n",
    "hd.plot_2D_histogram(df_dict, evt_list=evts_peak, detector1=\"TOF00\", quantity1=\"PeakTime\", detector2=\"TOF10\", quantity2=\"PeakTime\", base_dir='plt_2d_peak', rnum=rnum, select_nonzero_peaks=True, logscale=False, nbins=20, range=[[40,90],[60,190]])\n",
    "hd.plot_2D_histogram(df_dict, evt_list=evts_peak, detector1=\"HD14\", quantity1=\"PeakTime\", detector2=\"PbGlass\", quantity2=\"PeakTime\", base_dir='plt_2d_peak', rnum=rnum, select_nonzero_peaks=True, logscale=False, nbins=20, range=[[75,125],[40,120]])\n",
    "hd.plot_2D_histogram(df_dict, evt_list=evts_peak, detector1=\"HD14\", quantity1=\"PeakTime\", detector2=\"TriggerScint\", quantity2=\"PeakTime\", base_dir='plt_2d_peak', rnum=rnum, select_nonzero_peaks=True, logscale=False, nbins=12, range=[[75,125],[160,185]])\n",
    "\n",
    "hd.plot_2D_histogram(df_dict, evt_list=evts_tail, detector1=\"HD14\", quantity1=\"PeakTime\", detector2=\"TOF10\", quantity2=\"PeakTime\", base_dir='plt_2d_tail', rnum=rnum, select_nonzero_peaks=True, logscale=False, nbins=20, range=[[75,125],[60,100]])\n",
    "hd.plot_2D_histogram(df_dict, evt_list=evts_tail, detector1=\"HD14\", quantity1=\"PeakTime\", detector2=\"TOF00\", quantity2=\"PeakTime\", base_dir='plt_2d_tail', rnum=rnum, select_nonzero_peaks=True, logscale=False, nbins=20, range=[[75,125],[40,90]])\n",
    "hd.plot_2D_histogram(df_dict, evt_list=evts_tail, detector1=\"TOF00\", quantity1=\"PeakTime\", detector2=\"TOF10\", quantity2=\"PeakTime\", base_dir='plt_2d_tail', rnum=rnum, select_nonzero_peaks=True, logscale=False, nbins=20, range=[[40,90],[60,190]])\n",
    "hd.plot_2D_histogram(df_dict, evt_list=evts_tail, detector1=\"HD14\", quantity1=\"PeakTime\", detector2=\"PbGlass\", quantity2=\"PeakTime\", base_dir='plt_2d_tail', rnum=rnum, select_nonzero_peaks=True, logscale=False, nbins=20, range=[[75,125],[40,120]])\n",
    "hd.plot_2D_histogram(df_dict, evt_list=evts_tail, detector1=\"HD14\", quantity1=\"PeakTime\", detector2=\"TriggerScint\", quantity2=\"PeakTime\", base_dir='plt_2d_tail', rnum=rnum, select_nonzero_peaks=True, logscale=False, nbins=12, range=[[75,125],[160,185]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f52f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd2_events = final_df[(final_df.total_hits == 1) & (final_df.hit_HD2 == 1)]['event'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HD14 = df_dict['HD14']\n",
    "df_HD14[df_HD14['event'].isin(hd2_events)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adce7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HD2 = df_dict['HD2']\n",
    "df_HD2_inpeak = df_HD2[df_HD2['event'].isin(evts_peak)]\n",
    "plt.hist(df_HD2_inpeak[df_HD2_inpeak.IntCharge > 0.01].IntCharge,bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8898f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the tail events control plots\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_tail, base_dir='plt_tail', rnum=rnum, quantity='nPeaks', select_nonzero_peaks=False, logscale=False, nbins=20)\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_tail, base_dir='plt_tail', rnum=rnum, quantity='timeStamp', select_nonzero_peaks=False, logscale=False, nbins=40)\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_tail, base_dir='plt_tail', rnum=rnum, quantity='triggerTime', select_nonzero_peaks=False, logscale=False, nbins=40)\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_tail, base_dir='plt_tail', rnum=rnum, quantity='Pedestal', select_nonzero_peaks=False, logscale=True, nbins=60)\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_tail, base_dir='plt_tail', rnum=rnum, quantity='PedestalSigma', select_nonzero_peaks=False, logscale=True, nbins=60)\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_tail, base_dir='plt_tail', rnum=rnum, quantity='PeakVoltage', select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_tail, base_dir='plt_tail', rnum=rnum, quantity='PeakTime', select_nonzero_peaks=True, logscale=False, nbins=40)\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_tail, base_dir='plt_tail', rnum=rnum, quantity='SignalTime', select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_tail, base_dir='plt_tail', rnum=rnum, quantity='IntCharge', select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "\n",
    "# Plot the peak events control plots\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_peak, base_dir='plt_peak', rnum=rnum, quantity='nPeaks', select_nonzero_peaks=False, logscale=False, nbins=20)\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_peak, base_dir='plt_peak', rnum=rnum, quantity='timeStamp', select_nonzero_peaks=False, logscale=False, nbins=40)\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_peak, base_dir='plt_peak', rnum=rnum, quantity='triggerTime', select_nonzero_peaks=False, logscale=False, nbins=40)\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_peak, base_dir='plt_peak', rnum=rnum, quantity='Pedestal', select_nonzero_peaks=False, logscale=True, nbins=60)\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_peak, base_dir='plt_peak', rnum=rnum, quantity='PedestalSigma', select_nonzero_peaks=False, logscale=True, nbins=60)\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_peak, base_dir='plt_peak', rnum=rnum, quantity='PeakVoltage', select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_peak, base_dir='plt_peak', rnum=rnum, quantity='PeakTime', select_nonzero_peaks=True, logscale=False, nbins=40)\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_peak, base_dir='plt_peak', rnum=rnum, quantity='SignalTime', select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "hd.plot_histograms_for_each_signal(df_dict, evt_list=evts_peak, base_dir='plt_peak', rnum=rnum, quantity='IntCharge', select_nonzero_peaks=True, logscale=False, nbins=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0096db74",
   "metadata": {},
   "source": [
    "#### Show the effects of the ACT and TOF cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe60d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts_all = (final_df.total_hits == 1) \n",
    "cuts_ACT0 = cuts_all #& (final_df.hit_ACT0 == 1)\n",
    "cuts_ACT1 = cuts_ACT0 & (final_df.hit_ACT1 == 1)\n",
    "cuts_ACT3 = cuts_ACT1 & (final_df.nohit_ACT3 == 1)\n",
    "\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_all]['LG_IntCharge'],bins=40,label=\"HD14\")\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_ACT0]['LG_IntCharge'],bins=40,label=\"HD14+ACT0\")\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_ACT1]['LG_IntCharge'],bins=40,label=\"HD14+ACT0/1\")\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_ACT3]['LG_IntCharge'],bins=40,label=\"HD14+ACT0/1/3\")\n",
    "\n",
    "plt.xlabel(\"Lead glass charge\",fontsize=14)\n",
    "plt.ylabel(\"Counts/bin\",fontsize=14)\n",
    "plt.title(f\"RUN 000{rnum}, p = + 0.7 GeV/c\",fontsize=20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3793f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts_all = (final_df.total_hits == 1) \n",
    "cuts_ACT0 = cuts_all #& (final_df.hit_ACT0 == 1)\n",
    "cuts_ACT1 = cuts_ACT0 & (final_df.hit_ACT1 == 1)\n",
    "cuts_ACT3 = cuts_ACT1 & (final_df.nohit_ACT3 == 1)\n",
    "\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_all]['LG_IntCharge'],bins=40,label=\"HD14\")\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_ACT0]['LG_IntCharge'],bins=40,label=\"HD14+ACT0\")\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_ACT1]['LG_IntCharge'],bins=40,label=\"HD14+ACT0/1\")\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_ACT3]['LG_IntCharge'],bins=40,label=\"HD14+ACT0/1/3\")\n",
    "\n",
    "plt.xlabel(\"Lead glass charge\",fontsize=14)\n",
    "plt.ylabel(\"Counts/bin\",fontsize=14)\n",
    "plt.title(f\"RUN 000{rnum}, p = + 0.7 GeV/c\",fontsize=20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d403126d",
   "metadata": {},
   "source": [
    "#### Count the number of events in the tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts_nominal = (final_df.hit_HD14 == 1) & (final_df.total_hits == 1) & (final_df.LG_nPeaks == 1)\n",
    "if(low_radiation):\n",
    "    cuts_timing = (final_df.hit_ACT1 == 1) & (final_df.nohit_ACT3 == 1) & \\\n",
    "              (final_df.hit_TOF0 == 1) & (final_df.hit_T2 == 1)\n",
    "else:\n",
    "    cuts_timing = (final_df.hit_ACT0 == 1) & \\\n",
    "                        (final_df.hit_ACT1 == 1) & (final_df.nohit_ACT3 == 1) & \\\n",
    "                        (final_df.hit_TOF0 == 1) & (final_df.hit_TOF1 == 1) & (final_df.hit_T2 == 1)\n",
    "normed=False\n",
    "    \n",
    "values_hd14 = final_df[cuts_nominal & cuts_timing]['LG_IntCharge']\n",
    "\n",
    "ntail = len(values_hd14[values_hd14 < 0.1])\n",
    "npeak = len(values_hd14[values_hd14 >= 0.1])\n",
    "ftail = ntail/(npeak+ntail)\n",
    "fpeak = npeak/(npeak+ntail)\n",
    "print(\"Number of counts < 0.1:\",ntail)\n",
    "print(\"Number of counts >= 0.1:\",npeak)\n",
    "print(\"Ratio of tail/total events:\",ftail)\n",
    "print(\"Ratio of peak/total events:\",fpeak)\n",
    "\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "h0 = plt.hist(values_hd14,bins=80,label=\"HD14\",range=[0,0.5],density=normed)\n",
    "plt.xlabel(\"Lead glass charge\",fontsize=18)\n",
    "plt.ylabel(\"Counts/bin\",fontsize=18)\n",
    "plt.title(f\"RUN 000{rnum}, p = + 0.8 GeV/c;\\n{ntail} tail events < 0.1 ({ftail*100:.2f}%), {npeak} peak events >= 0.1 ({fpeak*100:.2f}%)\",fontsize=20)\n",
    "plt.legend(fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c4a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0721b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts_all = (final_df.total_hits == 1) \n",
    "cuts_TOF0 = cuts_all & (final_df.hit_TOF0 == 1)\n",
    "cuts_TOF1 = cuts_TOF0 & (final_df.hit_TOF1 == 1)\n",
    "cuts_T2 = cuts_TOF1 & (final_df.hit_T2 == 1)\n",
    "\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_all]['LG_IntCharge'],bins=40,label=\"HD14\")\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_TOF0]['LG_IntCharge'],bins=40,label=\"HD14+TOF0\")\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_TOF1]['LG_IntCharge'],bins=40,label=\"HD14+TOF0/1\")\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_T2]['LG_IntCharge'],bins=40,label=\"HD14+TOF0/1/2\")\n",
    "\n",
    "plt.xlabel(\"Lead glass charge\",fontsize=14)\n",
    "plt.ylabel(\"Counts/bin\",fontsize=14)\n",
    "plt.title(\"RUN 000734, p = + 0.7 GeV/c\",fontsize=20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14544ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(df_dict['ACT3L'][df_dict['ACT3L']['PeakTime'] > 10]['PeakTime'],bins=100)\n",
    "plt.hist(df_dict['ACT1L'][df_dict['ACT1L']['PeakTime'] > 10]['PeakTime'],bins=100)\n",
    "#plt.hist(act0_combined['combined_charge'],bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tof1_combined['combined_charge'],bins=100,range=[0,1])\n",
    "#plt.hist(df_dict['TOF00']['PeakTime'],bins=100,range=[35,90])\n",
    "#plt.hist(df_dict['TriggerScint']['IntCharge'],bins=100,range=[0,0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed19cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = uproot.open(\"{}\".format(\"../ntuples/ntuple_000734.root\"))\n",
    "main_keys = events.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db566634",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d74f0a",
   "metadata": {},
   "source": [
    "# 2. Plots of magnetic field map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ffacf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the field map.\n",
    "df = pd.read_csv('mfMapMeasured.txt', delim_whitespace=True, comment='%', header=None)\n",
    "\n",
    "# Assign column names\n",
    "df.columns = ['x', 'y', 'z', 'Bx', 'By', 'Bz']\n",
    "\n",
    "# Compute the magnitude of the field\n",
    "df['Bmag'] = np.sqrt(df['Bx']**2 + df['By']**2 + df['Bz']**2)\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2889b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['y'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe8446b",
   "metadata": {},
   "source": [
    "#### 1D plot (*fig.fieldmap*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208d7f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_center = df[(df['y'] == 0) & (df['x'] == 0)]\n",
    "df_r1 = df[(df['y'] == 0) & (df['x'] == 15.0)]\n",
    "\n",
    "# Central axis\n",
    "By_center = df_center['By'].values\n",
    "z_center  = df_center['z'].values\n",
    "\n",
    "# Off-axis near smallest bore edge\n",
    "By_r1 = df_r1['By'].values\n",
    "z_r1  = df_r1['z'].values\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(z_center,By_center,linewidth=1,color='black',label=\"B$_y$ (r = 0 mm)\")\n",
    "plt.plot(z_r1,By_r1,linewidth=1,color='black',linestyle='--',label=\"B$_y$ (r = 15 mm)\")\n",
    "plt.gca().tick_params(axis=\"x\", labelsize=14)\n",
    "plt.gca().tick_params(axis=\"y\", labelsize=14)\n",
    "plt.xlabel('Z (mm)',fontsize=14)\n",
    "plt.ylabel('B$_{y}$ (T)',fontsize=14)\n",
    "plt.legend(fontsize=17,loc=4)\n",
    "plt.savefig(\"Bfieldmap_axial.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z_center[By_center < -1.35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad12f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[(df['y'] == 0) & (df['x'] == 0)]\n",
    "Bx = df_filtered['Bx'].values\n",
    "By = df_filtered['By'].values\n",
    "Bz = df_filtered['Bz'].values\n",
    "z  = df_filtered['z'].values\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(z,Bx,linewidth=2,color='red', label=\"B$_x$\")\n",
    "plt.plot(z,By,linewidth=2,color='black', label=\"B$_y$\")\n",
    "plt.plot(z,Bz,linewidth=2,color='blue', label=\"B$_z$\")\n",
    "plt.gca().tick_params(axis=\"x\", labelsize=14)\n",
    "plt.gca().tick_params(axis=\"y\", labelsize=14)\n",
    "plt.xlabel('Z (mm)',fontsize=14)\n",
    "plt.ylabel('B$_{x,y,z}$ (T)',fontsize=14)\n",
    "plt.legend(fontsize=18,loc=4)\n",
    "plt.savefig(\"Bfieldmap_axial.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e746a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bd = np.trapz(z_center,By_center)/1000\n",
    "print(f\"Integrated field By = {Bd} T*m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ccd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geant4 field\n",
    "z = np.linspace(-500,500,100)\n",
    "fwhm_to_sigma = (2*(2*np.log(2))**0.5)\n",
    "sigma = 150 / fwhm_to_sigma\n",
    "bfield = -1.441*np.exp(-z**2/(2*sigma**2))\n",
    "plt.plot(z,bfield)\n",
    "plt.ylabel(\"B$_y$ (T)\",fontsize=16)\n",
    "plt.xlabel(\"z (mm)\",fontsize=16)\n",
    "#print(f\"FWHM to sigma conversion factor: {fwhm_to_sigma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50146a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bd_sim = np.trapz(z,bfield)/1000\n",
    "print(f\"Integrated field simulated in Geant4 = {Bd_sim} T*m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeffb5c2",
   "metadata": {},
   "source": [
    "#### 2D plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff5597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataframe for a specific y-plane, for example, y=0\n",
    "y_plane = 0\n",
    "#df_filtered = df[(df['y'] == y_plane) & (df['z'] > -100) & (df['z'] < 250)]\n",
    "df_filtered = df[df['y'] == y_plane]\n",
    "\n",
    "# Create a pivot table for the magnitude values\n",
    "pivot = df_filtered.pivot(index='x', columns='z', values='Bmag').fillna(0)\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.imshow(pivot, aspect='auto', cmap='viridis', origin='lower', \n",
    "           extent=[pivot.columns.min(), pivot.columns.max(), pivot.index.min(), pivot.index.max()])\n",
    "plt.colorbar(label='Field Magnitude (T)')\n",
    "plt.title(f'Magnetic Field Magnitude in x-z plane at Y={y_plane}')\n",
    "plt.xlabel('Z (mm)')\n",
    "plt.ylabel('X (mm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe79e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataframe for a specific z-plane, e.g., z=0\n",
    "z_plane = 75\n",
    "df_filtered = df[df['z'] == z_plane]\n",
    "arrow_scale = 1\n",
    "\n",
    "# Create the quiver (arrow) plot\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.quiver(df_filtered['x'], df_filtered['y'], arrow_scale*df_filtered['Bx'], arrow_scale*df_filtered['By'], \n",
    "           angles='xy', scale_units='xy', scale=1, color='blue', width=0.002)\n",
    "plt.title(f'Magnetic Field Direction in x-y plane at Z={z_plane}')\n",
    "plt.xlabel('X (mm)')\n",
    "plt.ylabel('Y (mm)')\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bc7391",
   "metadata": {},
   "source": [
    "### Extend the magnetic field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d661b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('mfMapMeasured.txt', delim_whitespace=True, comment='%', \n",
    "                   header=None, names=['X', 'Y', 'Z', 'Bx', 'By', 'Bz'])\n",
    "\n",
    "# Generate additional points\n",
    "new_points_range = np.arange(-40, 40.1, 2.5)  # Including +/- 40 mm with a step size of 2.5 mm\n",
    "\n",
    "# Initialize a list to collect new rows\n",
    "new_rows = []\n",
    "\n",
    "# Magnet radii\n",
    "r1 = 30  # mm; bore radius 1 = 23\n",
    "r2 = 40  # mm; bore radius 2 = 31\n",
    "r3 = 45  # mm; bore radius 3 = 40\n",
    "deltaZ = 50 # mm; length of one magnet segment (3 in total)\n",
    "\n",
    "ipt = 0\n",
    "zpoints = data['Z'].unique()\n",
    "npts = len(zpoints)*len(new_points_range)**2\n",
    "for z in zpoints:\n",
    "    # Find the set of existing X and Y for this Z to avoid duplicates\n",
    "    existing_xy = data[data['Z'] == z][['X', 'Y']].drop_duplicates()\n",
    "\n",
    "    for x in new_points_range:\n",
    "        for y in new_points_range:\n",
    "            # Check if this X, Y combination is new\n",
    "            if not ((existing_xy['X'] == x) & (existing_xy['Y'] == y)).any():\n",
    "                # Find the closest existing point in the original data for this Z\n",
    "                # Using Euclidean distance for simplicity; this could be adjusted as needed\n",
    "                distances = np.sqrt((data['X'] - x)**2 + (data['Y'] - y)**2 + (data['Z'] - z)**2)\n",
    "                closest_index = distances.idxmin()\n",
    "                closest_point = data.loc[closest_index]\n",
    "                \n",
    "                # Ensure the field is within the allowed region.\n",
    "                isInside = False\n",
    "                r = (x**2 + y**2)**0.5\n",
    "                if (z <= 0                         and r <= r1): isInside = True  # pre-magnet\n",
    "                if (z > 0        and z < deltaZ    and r <= r1): isInside = True  # region 1\n",
    "                if (z > deltaZ   and z <= 2*deltaZ and r <= r2): isInside = True  # region 2\n",
    "                if (z > 2*deltaZ and z <= 3*deltaZ and r <= r3): isInside = True  # region 3\n",
    "                if (z > 3*deltaZ                   and r <= r3): isInside = True  # post-magnet\n",
    "                \n",
    "                # Set the field.\n",
    "                if(isInside):\n",
    "                    Bx = closest_point['Bx']\n",
    "                    By = closest_point['By']\n",
    "                    Bz = closest_point['Bz']\n",
    "                    #print(f\"Adding field {Bx},{By},{Bz} at ({x},{y},{z}) with closest point {closest_point['X']},{closest_point['X']},{closest_point['X']}\")\n",
    "                else:\n",
    "                    Bx = 0\n",
    "                    By = 0\n",
    "                    Bz = 0\n",
    "\n",
    "                # Create a new row with this X, Y, Z and the Bx, By, Bz from the closest point\n",
    "                new_row = {'X': x, 'Y': y, 'Z': z, 'Bx': Bx, 'By': By, 'Bz': Bz}\n",
    "                new_rows.append(new_row)\n",
    "                \n",
    "            ipt += 1\n",
    "            if(ipt % 1000 == 0):\n",
    "                print(f\"[pt {ipt}] of possible {npts} ({ipt/npts*100:.1f})%\")\n",
    "\n",
    "# Convert the list of new rows to a DataFrame\n",
    "print(\"Creating new dataframe...\")\n",
    "new_points_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# Combine with the original data and sort\n",
    "print(\"Sorting...\")\n",
    "combined_data = pd.concat([data, new_points_df], ignore_index=True)\n",
    "combined_data = combined_data.sort_values(by=['Z', 'Y', 'X'], ascending=[True, True, True])\n",
    "\n",
    "# Save to a new file\n",
    "print(\"Saving...\")\n",
    "extrapolated_file_path = 'mfMapMeasured_extrapolated.txt'\n",
    "combined_data.to_csv(extrapolated_file_path, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['Z'].unique())*len(new_points_range)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d285d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_points_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2131e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "13*13*320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e568816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec86238",
   "metadata": {},
   "source": [
    "# 3. Waveform analysis (*fig.waveform*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7c6a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json5\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import waveform_analysis as wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3c9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the run file and config file.\n",
    "run_file = uproot.open(\"root_run_000735.root\")\n",
    "config = json5.load(open(\"../../../config/config_hodoscope.json\"))['WaveAnalysis']\n",
    "\n",
    "# Load the waveforms for HD14.\n",
    "waveforms_HD14 = run_file['midas_data_D302']['Channel7'].array().to_numpy()\n",
    "\n",
    "# Run the analysis of the waveforms.\n",
    "analysis = wf.WaveformAnalysis(waveforms_HD14,\n",
    "                            threshold=config[\"Thresholds\"][0],\n",
    "                            analysis_window=(config[\"AnalysisWindowLow\"][0], config[\"AnalysisWindowHigh\"][0]),\n",
    "                            pedestal_window=(config[\"PedestalWindowLow\"][0], config[\"PedestalWindowHigh\"][0]),\n",
    "                            reverse_polarity=(config[\"Polarity\"][0]==0),\n",
    "                            voltage_scale=config[\"VoltageScale\"],\n",
    "                            time_offset=config[\"TimeOffset\"][0])\n",
    "analysis.find_all_peak_voltages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0249fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "evt = 20675\n",
    "base_dir = \"plt_waveforms\"\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(7,4))\n",
    "fig.tight_layout()\n",
    "axs.plot(waveforms_HD14[evt][0:220],color='black')\n",
    "#plt.title(f\"\")\n",
    "\n",
    "# Iterate over peak times and plot arrows\n",
    "for peak in analysis.pulse_peak_times[evt]:\n",
    "\n",
    "    # Divide out the 2 ns / sample.\n",
    "    peak_sample = int(peak/2)\n",
    "    \n",
    "    # Get the corresponding ADC count for the peak time\n",
    "    y_peak = waveforms_HD14[evt][int(peak/2)]\n",
    "    \n",
    "    # Plot the arrow. The -5 in dy is arbitrary and used to offset the arrow tip for visibility.\n",
    "    axs.arrow(peak_sample, y_peak-400, 0, 15, head_width=5, head_length=250, fc='red', ec='red')\n",
    "\n",
    "axs.grid(alpha=0.4)\n",
    "axs.set_xlabel(\"Sample (2 ns)\",fontsize=14)\n",
    "axs.set_ylabel(\"ADC counts\",fontsize=14)\n",
    "axs.tick_params(axis=\"x\", labelsize=14)\n",
    "axs.tick_params(axis=\"y\", labelsize=14)\n",
    "\n",
    "# Label the different regions\n",
    "axs.axvspan(0, 100, color='red', alpha=0.1)\n",
    "axs.axvspan(150, 210, color='lightblue', alpha=0.5)\n",
    "axs.text(20, 8500, 'Analysis', ha='center', va='top', fontsize=12, fontweight='bold', color='black')\n",
    "axs.text(170, 8500, 'Pedestal', ha='center', va='top', fontsize=12, fontweight='bold', color='black')\n",
    "\n",
    "out_dir = f\"{base_dir}/HD14\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "plt.savefig(f\"{out_dir}/wf_HD14_{evt}.pdf\", bbox_inches='tight')\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee03df",
   "metadata": {},
   "source": [
    "# 4. Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3027037f",
   "metadata": {},
   "source": [
    "### Create dataframes for all runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8b02a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntuple_dir = \"/Users/jrenner/local/jerenner/T9BeamTestAna/ntuple/\"\n",
    "ntuple_pd_dir = \"/Users/jrenner/local/jerenner/T9BeamTestAna/ntuple_dataframes/\"\n",
    "windowInt = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c5469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs = np.arange(630,766)\n",
    "runs = [735]\n",
    "for run in runs:\n",
    "    ntuple_file = \"{}/WindowIntMatched_final_000735.root\".format(ntuple_dir,run)\n",
    "    #ntuple_file = \"{}/peakAnalysed_timeCorr_000735.root\".format(ntuple_dir,run)\n",
    "    output_dir = \"{}/run000{}\".format(ntuple_pd_dir,run)\n",
    "    \n",
    "    # Make sure the file exists\n",
    "    if(not os.path.isfile(ntuple_file)):\n",
    "        continue\n",
    "    \n",
    "    print(\"Creating dataframes for run\",run,\"...\")\n",
    "    \n",
    "    # Create the dataframe dictionary\n",
    "    df_dict = hd.ntuple_to_pd_multipeak(ntuple_file,windowInt=windowInt)\n",
    "\n",
    "    # Save all the dataframes for this run\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for key, df in df_dict.items():\n",
    "        filepath = os.path.join(output_dir, f\"{key}.csv\")\n",
    "        df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a15e95",
   "metadata": {},
   "source": [
    "### Plot all quantities for each signal for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9b017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [735] #np.arange(786,788)\n",
    "for run in runs:\n",
    "    rnum = f\"000{run}\"\n",
    "    run_dir = \"{}/run{}\".format(ntuple_pd_dir, rnum)\n",
    "    \n",
    "    # Make sure the run exists\n",
    "    if(run < 720 or not os.path.isdir(run_dir)):\n",
    "        continue\n",
    "        \n",
    "    print(\"Computing statistics for run\",run)\n",
    "\n",
    "    # Read in all dataframes for this run\n",
    "    df_dict = hd.read_dataframes_from_csv(run_dir)\n",
    "    \n",
    "    hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='timeStamp', windowInt=windowInt, select_nonzero_peaks=False, logscale=False, nbins=40)\n",
    "    hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='triggerTime', windowInt=windowInt, select_nonzero_peaks=False, logscale=False, nbins=40)\n",
    "    hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='Pedestal', windowInt=windowInt, select_nonzero_peaks=False, logscale=True, nbins=60)\n",
    "    hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='PedestalSigma', windowInt=windowInt, select_nonzero_peaks=False, logscale=True, nbins=60)\n",
    "    \n",
    "    hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='MaxVoltage', windowInt=windowInt, select_nonzero_peaks=False, logscale=False, nbins=60)\n",
    "    hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='WholeWaveformInt', windowInt=windowInt, select_nonzero_peaks=False, logscale=False, nbins=60)\n",
    "    hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='WholeWaveformIntPE', windowInt=windowInt, select_nonzero_peaks=False, logscale=False, nbins=60)\n",
    "    \n",
    "    if(windowInt):\n",
    "        hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='nWindowPeaks', windowInt=windowInt, select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "        hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='SignalTimeMatchedTOF0', windowInt=windowInt, select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "        hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='SignalTimeMatchedTOF1', windowInt=windowInt, select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "        hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='WindowIntCharge', windowInt=windowInt, select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "        hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='WindowIntPE', windowInt=windowInt, select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "        hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='WindowWidth', windowInt=windowInt, select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "        hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='WindowLowerTime', windowInt=windowInt, select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "        hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='WindowUpperTime', windowInt=windowInt, select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "        hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='WindowCentralTime', windowInt=windowInt, select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "        hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='WindowCentralTimeCorrected', windowInt=windowInt, select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "    else:\n",
    "        hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='nPeaks', windowInt=windowInt, select_nonzero_peaks=False, logscale=False, nbins=20)\n",
    "        hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='PeakVoltage', windowInt=windowInt, select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "        hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='PeakTime', windowInt=windowInt, select_nonzero_peaks=True, logscale=False, nbins=40)\n",
    "        hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='SignalTime', windowInt=windowInt, select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "        hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='SignalTimeCorrected', windowInt=windowInt, select_nonzero_peaks=False, logscale=False, nbins=60)\n",
    "        hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='IntCharge', windowInt=windowInt, select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "        hd.plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='IntPE', windowInt=windowInt, select_nonzero_peaks=True, logscale=False, nbins=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a44415",
   "metadata": {},
   "source": [
    "## Compute and plot statistics for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_data = {}\n",
    "\n",
    "runs = np.arange(630,766)\n",
    "for run in runs:\n",
    "    run_dir = \"{}/run000{}\".format(ntuple_pd_dir, run)\n",
    "    \n",
    "    # Make sure the run exists\n",
    "    if(run < 720 or not os.path.isdir(run_dir)):\n",
    "        continue\n",
    "        \n",
    "    print(\"Computing statistics for run\",run)\n",
    "\n",
    "    # Read in all dataframes for this run\n",
    "    df_dict = hd.read_dataframes_from_csv(run_dir)\n",
    "    \n",
    "    # Compute statistics for this run and save them\n",
    "    statistics_data[run] = {}\n",
    "    for key in custom_order:\n",
    "        statistics_data[run][key] = hd.compute_statistics(df_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893f83db",
   "metadata": {},
   "source": [
    "#### Plot summary statistics from each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc9800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_keys = ['avg_nPeaks', 'avg_Pedestal', 'avg_PedestalSigma', 'peak_PeakVoltage', 'peak_PeakTime', 'peak_SignalTime', 'peak_IntCharge']\n",
    "act_set = ['ACT0L', 'ACT0R', 'ACT1L', 'ACT1R', 'ACT3L', 'ACT3R', 'PbGlass']\n",
    "tof_set = ['TOF00', 'TOF01', 'TOF02', 'TOF03', 'TOF10', 'TOF11', 'TOF12', 'TOF13', 'TriggerScint']\n",
    "hd_set  = ['HD0', 'HD1', 'HD2', 'HD3', 'HD4', 'HD5', 'HD6', 'HD7', 'HD8', 'HD9', 'HD10', 'HD11', 'HD12', 'HD13', 'HD14']\n",
    "\n",
    "hd.plot_statistics_vs_run(statistics_data, statistics_keys, act_set, base_dir='plt', signal_set_name='ACT')\n",
    "hd.plot_statistics_vs_run(statistics_data, statistics_keys, tof_set, base_dir='plt', signal_set_name='TOF')\n",
    "hd.plot_statistics_vs_run(statistics_data, statistics_keys, hd_set, base_dir='plt', signal_set_name='HD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c499169",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ea2ec1",
   "metadata": {},
   "source": [
    "# OLD CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a4fae3",
   "metadata": {},
   "source": [
    "## Single-peak analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0684cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing and charge ranges for filters.\n",
    "pb_timing_range = (45, 75)\n",
    "tof0_timing_range = (45, 85)\n",
    "tof0_charge_range = (0.3, 1.0)\n",
    "tof1_timing_range = (60, 100)\n",
    "tof1_charge_range = (0.3, 1.0)\n",
    "t2_timing_range = (160, 180)\n",
    "t2_charge_range = (0.01, 0.0225)\n",
    "act0_timing_range = (130, 175)\n",
    "act0_charge_range = (0.1, 1.0)\n",
    "act1_timing_range = (130, 175)\n",
    "act1_charge_range = (0.02, 0.2)\n",
    "act3_timing_range = (150, 190)\n",
    "hd_timing_ranges = {\n",
    "    'HD0': (35, 75),\n",
    "    'HD1': (35, 75),\n",
    "    'HD2': (35, 75),\n",
    "    'HD3': (35, 75),\n",
    "    'HD4': (35, 75),\n",
    "    'HD5': (35, 75),\n",
    "    'HD6': (35, 75),\n",
    "    'HD7': (35, 75),\n",
    "    'HD8': (80, 120),\n",
    "    'HD9': (80, 120),\n",
    "    'HD10': (80, 120),\n",
    "    'HD11': (80, 120),\n",
    "    'HD12': (80, 120),\n",
    "    'HD13': (80, 120),\n",
    "    'HD14': (80, 120)\n",
    "}\n",
    "hd_charge_ranges = {\n",
    "    'HD0': (0.12, 0.3),\n",
    "    'HD1': (0.09, 0.2),\n",
    "    'HD2': (0.06, 0.15),\n",
    "    'HD3': (0.075, 0.2),\n",
    "    'HD4': (0.075, 0.2),\n",
    "    'HD5': (0.1, 0.3),\n",
    "    'HD6': (0.1, 0.3),\n",
    "    'HD7': (0.1, 0.3),\n",
    "    'HD8': (0.085, 0.285),\n",
    "    'HD9': (0.085, 0.285),\n",
    "    'HD10': (0.1, 0.3),\n",
    "    'HD11': (0.075, 0.275),\n",
    "    'HD12': (0.1, 0.3),\n",
    "    'HD13': (0.1, 0.4),\n",
    "    'HD14': (0.1, 0.4)    \n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
